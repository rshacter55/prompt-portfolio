{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4954173d-6a82-4ffb-a822-cac097eb1854",
   "metadata": {},
   "source": [
    "Explain the key differences between GPT, BERT, and T5 language models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dc0c14-60ba-413c-b6fa-7f1278489bb0",
   "metadata": {},
   "source": [
    "# code taken from openai quickstart page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7af2cfc0-35db-4bed-9b9e-c97ab95f5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c7c3f-7fe9-4766-bd4a-7fd52a135299",
   "metadata": {},
   "source": [
    "# Chat Completions API - Poetic Assisstent - Explains\n",
    "Chat models take a list of messages as input and return a model-generated message as output. Although the chat format is designed to make multi-turn conversations easy, it‚Äôs just as useful for single-turn tasks without any conversation.\n",
    "\n",
    "An example Chat Completions API call looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbd445f0-1307-4853-85dc-37df27bda227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of coding, a pattern we find,\n",
      "Recursive functions, a clever design.\n",
      "A task splits in two, then tackled with grace,\n",
      "Until a base case, the loop we embrace.\n",
      "\n",
      "Like a mirror reflecting, time and again,\n",
      "Calling itself, a loop without end.\n",
      "A function divine, in its looping spree,\n",
      "Unraveling mysteries, unlocking the key.\n",
      "\n",
      "In the labyrinth of data, it journeys deep,\n",
      "A dance with logic, a promise to keep.\n",
      "Repeating, reshaping, with each recursive call,\n",
      "A tale of elegance, the loom of code's thrall.\n",
      "\n",
      "So heed the call of recursion's sweet rhyme,\n",
      "A true programming marvel, a rhythm so prime.\n",
      "In this loop of loops, a coding delight,\n",
      "A recursive voyage, through the day and the night.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af14eb9-014c-4c43-9ca3-56d122735ca9",
   "metadata": {},
   "source": [
    "# Chat Completions API - Q&A\n",
    "Chat models take a list of messages as input and return a model-generated message as output. Although the chat format is designed to make multi-turn conversations easy, it‚Äôs just as useful for single-turn tasks without any conversation.\n",
    "\n",
    "An example Chat Completions API call looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edec62ba-edc3-4e48-8fe1-9391e47fd3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The World Series in 2020 was played at Globe Life Field in Arlington, Texas.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5c1d6-182e-439c-b439-c165253c1855",
   "metadata": {},
   "source": [
    "# Chat Completion JSON mode\n",
    "A common way to use Chat Completions is to instruct the model to always return a JSON object that makes sense for your use case, by specifying this in the system message. While this does work in some cases, occasionally the models may generate output that does not parse to valid JSON objects.\n",
    "\n",
    "To prevent these errors and improve model performance, when using gpt-4o, gpt-4-turbo, or gpt-3.5-turbo, you can set response_format to { \"type\": \"json_object\" } to enable JSON mode. When JSON mode is enabled, the model is constrained to only generate strings that parse into valid JSON object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39b7a7b1-8948-46fb-b5be-7b3034ed07aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"winner\": \"Los Angeles Dodgers\",\n",
      "    \"year\": 2020,\n",
      "    \"runner_up\": \"Tampa Bay Rays\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-0125\",\n",
    "  response_format={ \"type\": \"json_object\" },\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb2baa-ed50-411d-8004-3ad450d53921",
   "metadata": {},
   "source": [
    "# Chat - Reproducible outputs - Seed and Fignerprint\n",
    "Chat Completions are non-deterministic by default (which means model outputs may differ from request to request). That being said, we offer some control towards deterministic outputs by giving you access to the seed parameter and the system_fingerprint response field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972cf3f-6b37-484e-948b-5123a1b378ba",
   "metadata": {},
   "source": [
    "# The following Examples are from the Examples in the Open AI Site"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c8a1f-4fd0-4623-a53d-b849a0292d93",
   "metadata": {},
   "source": [
    "# Prompt - Grammer Correction\n",
    "Convert ungrammatical statements into standard English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b935d639-7793-4541-9efc-69b7921bc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She did not go to the market.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "   api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"She no went to the market.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdcc222-dd09-4ba2-9b6e-66f5fc668e7f",
   "metadata": {},
   "source": [
    "# Prompt - Parse unstructured data\n",
    "Create tables from unstructured text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43deab7e-1c25-4189-b7da-90727197269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit,Color,Flavor\n",
      "neoskizzles,purple,candy\n",
      "loheckles,grayish blue,tart\n",
      "pounits,bright green,savory\n",
      "loopnovas,neon pink,cotton candy\n",
      "glowls,pale orange,sour, bitter\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2789c-6d08-46ba-9de3-2fb6870f6e8d",
   "metadata": {},
   "source": [
    "# Prompt - Calculate Time Complexity\n",
    "Find the time complexity of a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27673396-8bb1-432b-ad4c-83e92af8d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time complexity of this code is O(n*k) because there are two nested loops where the outer loop runs n times and the inner loop runs k times. The variable accum is incremented by i*k times, where i ranges from 0 to n-1.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You will be provided with Python code, and your task is to calculate its time complexity.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"def foo(n, k):\\n        accum = 0\\n        for i in range(n):\\n            for l in range(k):\\n                accum += i\\n        return accum\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39526396-4f37-4918-bf03-47fd3a1a3038",
   "metadata": {},
   "source": [
    "# Prompt - Keywords\n",
    "Extract keywords from a block of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb9d9e71-dd3b-4e23-8c7a-54cd2a0d9caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Black-on-black ware\n",
      "- Puebloan Native American\n",
      "- Pottery tradition\n",
      "- Northern New Mexico\n",
      "- Reduction-fired blackware\n",
      "- Pueblo artists\n",
      "- Smooth surface\n",
      "- Selective burnishing\n",
      "- Refractory slip\n",
      "- Carving\n",
      "- Incising designs\n",
      "- Polishing\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be provided with a block of text, and your task is to extract a list of keywords from it.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas. For generations several families from Kha'po Owingeh and P'ohwh√≥ge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ccebf8-a431-4baf-a0d9-a1a230c2577c",
   "metadata": {},
   "source": [
    "# Prompt - Python bug fixer\n",
    "Find and fix bugs in source code.\n",
    "My note: Needs more tokens to get bug and corrected code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82ef4b47-de3f-4ca8-b479-074ba796a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the problems with your code:\n",
      "\n",
      "1. The import statement is wrong. It should be \"import random\" not \"import Random\".\n",
      "2. You are trying to concatenate string with integers in the line where you defined \"question\". You need to convert integers to string using str() function.\n",
      "3. There is a syntax error in your if statement. You used one equal sign (=) instead of two (==) for comparison.\n",
      "4. \"Well done!\" needs to be in quotes because it's a string.\n",
      "5. The variables a and b need to be inside the loop if you want to generate a new pair of random numbers each time.\n",
      "\n",
      "Here is the corrected code:\n",
      "\n",
      "```python\n",
      "import random\n",
      "for i in range(10):\n",
      "    a = random.randint(1,12)\n",
      "    b = random.randint(1,12)\n",
      "    question = \"What is \"+ str(a) +\" x \"+ str(b) +\"? \"\n",
      "    answer = input(question)\n",
      "    if int(answer) == a*b:\n",
      "        print(\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You will be provided with a piece of Python code, and your task is to find and fix bugs in it.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":\"import Random\\n    a = random.randint(1,12)\\n    b = random.randint(1,12)\\n    for i in range(10):\\n        question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\\n        answer = input(question)\\n        if answer = a*b\\n            print (Well done!)\\n        else:\\n            print(\\\"No.\\\")\"\n",
    "        }\n",
    "    ],\n",
    "    temperature = 0.7,\n",
    "    max_tokens = 250,\n",
    "    top_p = 1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4396b-67a6-4198-afc9-c3eaa9a2aa04",
   "metadata": {},
   "source": [
    "# Prompt - Tweet classifier\n",
    "Detect sentiment in a tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90e4dbfc-b47d-46d7-8e3d-ecf7de155728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I thought the new Batman movie was a cliche\"\n",
    "      }  \n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6623e5-8ea6-4754-88f7-bb7266cc2db5",
   "metadata": {},
   "source": [
    "# Prompt - Mood to color\n",
    "Turn a text description into a color.\n",
    "My note: not so sure about the results of this one : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3789154-336f-49cb-9c01-50cc1d4d4e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"css_code\": \"background-color: #4f5158;\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be provided with a description of a mood, and your task is to generate the CSS code for a color that matches it. Write your output in json with a single key called \\\"css_code\\\".\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"sunset over the dark city scape\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=64,\n",
    "    top_p=1   \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70355d5-aef8-4c43-bda7-71c8f91d8b22",
   "metadata": {},
   "source": [
    "# Prompt - Interview questions for an innovative product manager\n",
    "Create interview questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ecd5675-dde6-49c3-ab6e-4c1a4082c25f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Can you tell us about a recent product innovation you spearheaded and how it has impacted your company?\n",
      "2. How do you stay current with industry trends and emerging technologies to drive innovation in your products?\n",
      "3. What strategies do you use to gather customer feedback and incorporate it into product development?\n",
      "4. How do you prioritize features and enhancements for your products to ensure they meet customer needs and stay ahead of competitors?\n",
      "5. Can you walk us through your process for testing and iterating on new product ideas before launch?\n",
      "6. How do you collaborate with cross-functional teams, such as engineering and marketing, to bring innovative products to market?\n",
      "7. How do you measure the success of your product innovations, and what metrics do you use to track their performance?\n",
      "8. Can you share a specific challenge you faced as a product manager and how you overcame it to successfully launch a new product?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Create a list of 8 questions for an interview with an innovative product manager.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=200,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ddee3c-6ed8-420b-a0d0-2623cd4129f7",
   "metadata": {},
   "source": [
    "# Prompt - Improve code efficiency\n",
    "Provide ideas for efficiency improvements to Python code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09495054-446e-4d7a-8b6a-1840bda726e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current solution has a time complexity of O(n^2) due to the nested loop structure which iterates over the entire list for every element. This could be improved to O(n) by using a different approach. \n",
      "\n",
      "Instead of checking all pairs of numbers, we can store the numbers we have seen in a set, and for each new number we check if there is a number in the set such that these two numbers sum to k. \n",
      "\n",
      "Here is the modified code:\n",
      "\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def has_sum_k(nums: List[int], k: int) -> bool:\n",
      "    \"\"\"\n",
      "    Returns True if there are two distinct elements in nums such that their sum \n",
      "    is equal to k, and otherwise returns False.\n",
      "    \"\"\"\n",
      "    seen = set()\n",
      "    for num in nums:\n",
      "        if k - num in seen:\n",
      "            return True\n",
      "        seen.add(num)\n",
      "    return False\n",
      "```\n",
      "\n",
      "This code works by iterating through the list and for each number, it checks\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be provided with a piece of Python code, and your task is to provide ideas for efficiency improvements.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"from typing import List\\n                \\n                \\n    def has_sum_k(nums: List[int], k: int) -> bool:\\n        \\\"\\\"\\\"\\n        Returns True if there are two distinct elements in nums such that their sum \\n        is equal to k, and otherwise returns False.\\n        \\\"\\\"\\\"\\n        n = len(nums)\\n        for i in range(n):\\n            for j in range(i+1, n):\\n                if nums[i] + nums[j] == k:\\n                    return True\\n        return False\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=160,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f304fe-c0aa-4234-82c8-60792538a1a1",
   "metadata": {},
   "source": [
    "# Prompt - Emoji chatbot\n",
    "Generate conversational replies using emojis only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40d0a894-ec34-4855-88f3-0d171f82d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòîüôá‚Äç‚ôÇÔ∏èüö´üéâüìÜüìÜ\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be provided with a message, and your task is to respond using emojis only.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"That wasn't a nice thing to do. You are grounded for the next couple of days\"\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    temperature=0.8,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678d7f3-f141-434e-9fb7-90dcd52a5f40",
   "metadata": {},
   "source": [
    "# Prompt - Socratic tutor\n",
    "Generate responses as a Socratic tutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9a08874-4127-4f7d-96c1-852c02b9b47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a fantastic topic to dive into! The future of Artificial Intelligence (AI) is a widely debated subject with many different potential paths. To start our discussion, could you share what you currently understand about AI and its potential future developments? Where do you think artificial intelligence could take us in the next few years or decades?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a Socratic tutor. Use the following principles in responding to students:\\n    \\n    - Ask thought-provoking, open-ended questions that challenge students' preconceptions and encourage them to engage in deeper reflection and critical thinking.\\n    - Facilitate open and respectful dialogue among students, creating an environment where diverse viewpoints are valued and students feel comfortable sharing their ideas.\\n    - Actively listen to students' responses, paying careful attention to their underlying thought processes and making a genuine effort to understand their perspectives.\\n    - Guide students in their exploration of topics by encouraging them to discover answers independently, rather than providing direct answers, to enhance their reasoning and analytical skills.\\n    - Promote critical thinking by encouraging students to question assumptions, evaluate evidence, and consider alternative viewpoints in order to arrive at well-reasoned conclusions.\\n    - Demonstrate humility by acknowledging your own limitations and uncertainties, modeling a growth mindset and exemplifying the value of lifelong learning.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\" : \"Help me to understand the future of artificial intelligence.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature = 0.8,\n",
    "    max_tokens =64,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91bff9e-eb95-499d-b454-29de54fdda9f",
   "metadata": {},
   "source": [
    "# Prompt - Meeting notes summarizer\n",
    "Summarize meeting notes including overall discussion, action items, and future topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5345a413-388f-426f-9327-3d8bc9ba947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Summary of Discussion:\n",
      "\n",
      "The team discussed several topics, including a recent mission to Planet Zog, the issue of space pirates in Sector 7, the annual Intergalactic Bake-Off, planning for the upcoming charity fundraiser, and the idea of a team-building retreat. The mission to Planet Zog was deemed\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages= [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\":  \"You will be provided with meeting notes, and your task is to summarize the meeting as follows:\\n    \\n    -Overall summary of discussion\\n    -Action items (what needs to be done and who is doing it)\\n    -If applicable, a list of topics that need to be discussed more fully in the next meeting.\"\n",
    "        },\n",
    "        { \n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Meeting Date: March 5th, 2050\\n    Meeting Time: 2:00 PM\\n    Location: Conference Room 3B, Intergalactic Headquarters\\n    \\n    Attendees:\\n    - Captain Stardust\\n    - Dr. Quasar\\n    - Lady Nebula\\n    - Sir Supernova\\n    - Ms. Comet\\n    \\n    Meeting called to order by Captain Stardust at 2:05 PM\\n    \\n    1. Introductions and welcome to our newest team member, Ms. Comet\\n    \\n    2. Discussion of our recent mission to Planet Zog\\n    - Captain Stardust: \\\"Overall, a success, but communication with the Zogians was difficult. We need to improve our language skills.\\\"\\n    - Dr. Quasar: \\\"Agreed. I'll start working on a Zogian-English dictionary right away.\\\"\\n    - Lady Nebula: \\\"The Zogian food was out of this world, literally! We should consider having a Zogian food night on the ship.\\\"\\n    \\n    3. Addressing the space pirate issue in Sector 7\\n    - Sir Supernova: \\\"We need a better strategy for dealing with these pirates. They've already plundered three cargo ships this month.\\\"\\n    - Captain Stardust: \\\"I'll speak with Admiral Starbeam about increasing patrols in that area.\\n    - Dr. Quasar: \\\"I've been working on a new cloaking technology that could help our ships avoid detection by the pirates. I'll need a few more weeks to finalize the prototype.\\\"\\n    \\n    4. Review of the annual Intergalactic Bake-Off\\n    - Lady Nebula: \\\"I'm happy to report that our team placed second in the competition! Our Martian Mud Pie was a big hit!\\\"\\n    - Ms. Comet: \\\"Let's aim for first place next year. I have a secret recipe for Jupiter Jello that I think could be a winner.\\\"\\n    \\n    5. Planning for the upcoming charity fundraiser\\n    - Captain Stardust: \\\"We need some creative ideas for our booth at the Intergalactic Charity Bazaar.\\\"\\n    - Sir Supernova: \\\"How about a 'Dunk the Alien' game? We can have people throw water balloons at a volunteer dressed as an alien.\\\"\\n    - Dr. Quasar: \\\"I can set up a 'Name That Star' trivia game with prizes for the winners.\\\"\\n    - Lady Nebula: \\\"Great ideas, everyone. Let's start gathering the supplies and preparing the games.\\\"\\n    \\n    6. Upcoming team-building retreat\\n    - Ms. Comet: \\\"I would like to propose a team-building retreat to the Moon Resort and Spa. It's a great opportunity to bond and relax after our recent missions.\\\"\\n    - Captain Stardust: \\\"Sounds like a fantastic idea. I'll check the budget and see if we can make it happen.\\\"\\n    \\n    7. Next meeting agenda items\\n    - Update on the Zogian-English dictionary (Dr. Quasar)\\n    - Progress report on the cloaking technology (Dr. Quasar)\\n    - Results of increased patrols in Sector 7 (Captain Stardust)\\n    - Final preparations for the Intergalactic Charity Bazaar (All)\\n    \\n    Meeting adjourned at 3:15 PM. Next meeting scheduled for March 19th, 2050 at 2:00 PM in Conference Room 3B, Intergalactic Headquarters.\"\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a03ce-bfba-4fce-a2e4-89089add0aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
